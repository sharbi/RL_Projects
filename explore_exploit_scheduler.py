import numpy as np
import torch

class Explore_Exploit_Sched:
    def __init__(self, DQN, n_actions, eps_initial=1, eps_final=0.1, eps_final_frame=0.01,
                eps_evaluation=0.0, eps_annealing_frames=1000000,
                replay_memory_start_size=50000, max_frames=25000000):

        """
        This function decides upon an action depending on the stage of training.
        It looks at the number of frames seen and returns an epsilon value that
        will decide how likely the algorithm is to explore. A higher epsilon means
        that the algorithm is more likely to return a random action, rather than
        the action with the highest Q-value.
        When the algorithm is being evaluated the epsilon is set to 0. This means
        there is absolutely no exploration and only the best action is chosen.
        """

        self.n_actions = n_actions
        self.eps_initial = eps_initial
        self.eps_final = eps_final
        self.eps_final_frame = eps_final_frame
        self.eps_evaluation = eps_evaluation
        self.eps_annealing_frames = eps_annealing_frames
        self.replay_memory_start_size = replay_memory_start_size
        self.max_frames = max_frames

        # calculate the slopes and intercepts during exploration decrease

        self.slope = -(self.eps_initial - self.eps_final)/self.eps_annealing_frames
        self.intercept = self.eps_initial - self.slope*self.replay_memory_start_size
        self.slope_2 = -(self.eps_final - self.eps_final_frame)/(self.max_frames - \
                        self.eps_annealing_frames - self.replay_memory_start_size)
        self.intercept_2 = self.eps_final_frame - self.slope_2*self.max_frames


        self.DQN = DQN

    def get_action(self, frame_number, state, evaluation=False):

        if evaluation:
            eps = self.eps_evaluation
        elif frame_number < self.replay_memory_start_size:
            eps = self.eps_initial
        elif frame_number >= self.replay_memory_start_size and frame_number < \
                        self.replay_memory_start_size + self.eps_annealing_frames:
            eps = self.slope*frame_number + self.intercept
        elif frame_number >= self.replay_memory_start_size + self.eps_annealing_frames:
            eps = self.slope_2*frame_number + self.intercept_2

        if np.random.rand(1) < eps:
            return np.random.randint(0, self.n_actions)
        else:
            state = torch.FloatTensor(state).float().unsqueeze(0).to(self.device)
            return np.argmax(self.DQN.forward(state).cpu().detach().numpy())
